
**Beispiele:** GPT, o-GPT, GEMINI...

### Wo werden LLM's eingesetzt?

##### Chat

- Eingaben des Nutzers werden an LLM Ã¼bertragen.
- LLM Verarbeitet die Eingabe des Benutzers (Prompt) incl. dem Chatverlauf, AnhÃ¤nge usw.
- LLM Ã¼bertrÃ¤gt die Antwort an den Chat-Prozess, der die Antwort im Chatverlauf anzeigt.

---

# Context Window

 Es beschreibt den **maximalen Umfang an Text**, den das Modell gleichzeitig "sehen" und berÃ¼cksichtigen kann, um eine Antwort zu generieren.

Ein Kontextfenster ist wie ein **GedÃ¤chtnisrahmen**:  
Das Modell kann nur eine bestimmte Anzahl von **Tokens** (also Textbausteinen wie WÃ¶rter oder Satzzeichen) gleichzeitig "im Kopf behalten" und daraus Schlussfolgern.

### ğŸ”¢ Beispiel mit Token-Anzahl

| Modell  | Kontextfenster (max. Tokens) |
| ------- | ---------------------------- |
| GPT-3   | 2.048 Tokens                 |
| GPT-3.5 | 4.096 Tokens                 |
| GPT-4   | 8.192 oder 32.768 Tokens     |
| GPT-4o  | bis zu 128.000 Tokens        |

- **1 Token â‰ˆ 0,75 WÃ¶rter (im Englischen)**.  
    Beispiel:  
    â†’ 100 Tokens â‰ˆ 75 englische WÃ¶rter  
    â†’ 1.000 Tokens â‰ˆ ~750 WÃ¶rter (~1 A4-Seite Text)  
    â†’ 128.000 Tokens â‰ˆ Ã¼ber 300 Seiten Text
    

---

### ğŸ§  Wozu dient das Kontextfenster?

- Es enthÃ¤lt:
    - deinen Prompt (Frage, Text, Code usw.)
    - vorherige Teile der Konversation
    - eventuell eingebettete Dokumente oder Chatverlauf

- Das Modell verwendet den gesamten Kontextfenster, um:
    - relevante Informationen zu erkennen
    - kohÃ¤rente Antworten zu geben
    - sich an frÃ¼here Anweisungen zu â€erinnernâ€œ


---

### ğŸ“‰ Begrenzung

Wenn du zu viel Text (z.â€¯B. ein ganzes Buch) eingibst, **wird der Anfang abgeschnitten**, sobald das Limit Ã¼berschritten wird. Das kann z.â€¯B. bedeuten, dass frÃ¼here Anweisungen verloren gehen, wenn du sehr lange Inputs verwendest.

---

### ğŸ›  Was zÃ¤hlt alles als Kontext?

- Deine Eingabe (â€Promptâ€œ)
    
- FrÃ¼here Eingaben und Ausgaben im Chat
    
- Systemanweisungen
    
- Eventuell: eingebundene Dateien oder Anmerkungen vom Benutzer
    

---

### ğŸ§© Warum ist das wichtig fÃ¼r Entwickler?

Wenn du mit GPT ein Tool oder Plugin entwickelst:

- Du musst im Auge behalten, **wie viele Tokens du verwendest**, sonst kommt es zu:
    
    - Fehlern (â€context length exceededâ€œ)
        
    - unerwartetem Verhalten (Modell ignoriert Teile)
        
- Manche Entwickler bauen explizite **Kontext-Management-Systeme**, die:
    
    - irrelevante Teile rausfiltern
        
    - den Kontext dynamisch zusammenfassen
        
    - oder vektorbasierte Retrieval-Systeme (RAG) verwenden